Classifying Real V.S. AI-Generated Artwork Images With ExplainableAI Analysis
Eugenie Choi
Advisor: Professor Xiaoyan Li
The currently existing artwork image dataset ArtBench was combined with images artificially generated by Stable Diffusion and DALLE-2 containing similar visual content. Two datasets were created, with half of each dataset consisting of real artwork images from the ArtBench-10 dataset, which contains 60K real artwork images from seven artistic styles. The other half of each dataset consisted of artwork images artificially generated by a text-to-image diffusion model under the same styles, depicting very similar content to that of the real images in the dataset. A discriminative convolutional neural network was then trained on the datasets to differentiate whether an image chosen from the test dataset was either a real or generated artwork image. The results of the discriminative model’s ability to classify real vs. fake images were then evaluated through multiple experiments using precision, recall, and accuracy metrics. The classifier’s evaluation metrics were high for both datasets, suggesting an overall success for the classifier’s ability to differentiate between classes. The classifier’s results were also visually interpreted using the ExplainableAI architecture LIME, which creates a heatmap of the features in each image that contribute to the class output label. Overall, the classifier results were very promising and LIME provided explanations for the classifier’s decisions, proving that the classifier can be used as a successful and faithful detector against synthetic art fraud or fabrications.
